%%=============================================================================
%% Samenvatting
%%=============================================================================

% TODO: De "abstract" of samenvatting is een kernachtige (~ 1 blz. voor een
% thesis) synthese van het document.
%
% Een goede abstract biedt een kernachtig antwoord op volgende vragen:
%
% 1. Waarover gaat de bachelorproef?
% 2. Waarom heb je er over geschreven?
% 3. Hoe heb je het onderzoek uitgevoerd?
% 4. Wat waren de resultaten? Wat blijkt uit je onderzoek?
% 5. Wat betekenen je resultaten? Wat is de relevantie voor het werkveld?
%
% Daarom bestaat een abstract uit volgende componenten:
%
% - inleiding + kaderen thema
% - probleemstelling
% - (centrale) onderzoeksvraag
% - onderzoeksdoelstelling
% - methodologie
% - resultaten (beperk tot de belangrijkste, relevant voor de onderzoeksvraag)
% - conclusies, aanbevelingen, beperkingen
%
% LET OP! Een samenvatting is GEEN voorwoord!

%%---------- Nederlandse samenvatting -----------------------------------------
%
% TODO: Als je je bachelorproef in het Engels schrijft, moet je eerst een
% Nederlandse samenvatting invoegen. Haal daarvoor onderstaande code uit
% commentaar.
% Wie zijn bachelorproef in het Nederlands schrijft, kan dit negeren, de inhoud
% wordt niet in het document ingevoegd.

\IfLanguageName{english}{%
\selectlanguage{dutch}
\chapter*{Samenvatting}

Het voorstel richt zich op het benchmarken van zelf-gehoste \glspl{LLM} om de effectiviteit van deze modellen te evalueren in het veilig ondersteunen van programmeerprocessen binnen bedrijfsomgevingen. Organisaties die gevoelige code verwerken, vermijden steeds vaker cloudgebaseerde \gls{AI}-modellen vanwege het risico dat modellen zoals ChatGPT of Gemini deze code opnemen in hun trainingssets of opslaan, wat leidt tot mogelijke blootstelling van bedrijfsgevoelige informatie.

De onderzoeksvraag luidt:
\begin{quote}
    “Welke zelf-gehoste \gls{LLM} biedt de beste ondersteuning voor codeertaken terwijl datalekrisico’s worden geminimaliseerd?”
\end{quote}

Het doel van de bachelorproef is om een gestructureerde evaluatie te bieden van de prestaties, nauwkeurigheid, efficiëntie en gebruiksvriendelijkheid van geselecteerde open-source \glspl{LLM}, zoals StarCoder en Mistral.

De methodologie omvat het opstellen van gestandaardiseerde benchmarks, zoals HumanEval en \gls{MBPP}, waarmee de modellen worden getest op een reeks programmeertaken in een gecontroleerde on-premise omgeving.

Verwacht wordt dat dit onderzoek niet alleen inzicht geeft in welke modellen technisch het meest geschikt zijn, maar ook praktische aanbevelingen biedt aan bedrijven voor het integreren van veilige \gls{AI}-oplossingen in hun ontwikkelprocessen. Hierdoor worden bedrijven ondersteund in hun zoektocht naar privacybewuste \gls{AI}-oplossingen, waarmee innovatie kan worden bevorderd zonder in te boeten op de veiligheid van gevoelige gegevens.

\selectlanguage{english}
}{}

%%---------- Samenvatting -----------------------------------------------------
% De samenvatting in de hoofdtaal van het document
\chapter*{\IfLanguageName{dutch}{Samenvatting}{Abstract}}

This proposal focuses on benchmarking self-hosted \glspl{LLM} to evaluate their effectiveness in securely supporting programming processes within enterprise environments. Organizations that handle sensitive code are increasingly avoiding cloud-based \gls{AI} models due to the risk that models such as ChatGPT or Gemini may incorporate inputted code into their training sets or store it, leading to potential exposure of sensitive business information.

The research question posed is:  
\begin{quote}
  “Which self-hosted \glspl{LLM} provides the best support for coding tasks while minimizing data-leakage risks?”
\end{quote}

The aim of this bachelor’s thesis is to provide a structured evaluation of the performance, accuracy, efficiency, and usability of selected open-source \glspl{LLM}, such as StarCoder and Mistral.

The methodology involves establishing standardized benchmarks, such as HumanEval and \gls{MBPP}, with which the models are tested on a series of programming tasks in a controlled on-premise environment.

It is expected that this research will not only provide insight into which models are technically most suitable, but also offer practical recommendations to companies for integrating secure \gls{AI} solutions into their development processes. In doing so, companies are supported in their quest for privacy-conscious \gls{AI} solutions, thereby fostering innovation without compromising the security of sensitive data.
